---
title: 'Biostatistics Task 1'
author: 'Danyu Zhang & Daniel Alonso'
date: 'May 1st, 2021'
output: 'pdf_document'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = '#>',
fig.path = './figures/'
)
knitr::knit_engines$set(julia = JuliaCall::eng_juliacall)
options(JULIA_HOME = '/home/dreth/julia/bin')
```

```{r, echo=TRUE, warning=FALSE, message=FALSE}
library(coin)
library(vcd)
library(dplyr)
library(mosaic)
library(qvalue)
library(broman)
```

# Exercise 2

```{r, echo=TRUE, warning=FALSE, message=FALSE}
groupA <- c(324,275,349,604,566,810,340,295,357,580,344,655,380,503,314)
groupB <- c(558,108,291,863,303,640,358,503,646,689,250,540,630,190)
groups_d <- factor(c(rep('A',length(groupA)), rep('B', length(groupB))))
values <- c(groupA, groupB)
groups <- data.frame(group=groups_d, ASO=values)
```

Performing a Shapiro-Wilk normality test tells us that the Group A likely is not normally distributed.

\small

```{r, echo=TRUE, warning=FALSE, message=FALSE}
shapiro.test(groupA)
shapiro.test(groupB)
```

\normalsize

## Standard Procedure

We don't reject the null hypothesis, therefore we can say there's no significant difference between the population median of each group.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
wilcox.test(ASO ~ group, data=groups)
```

## Resampling Method: Permutation Test

As with the standard procedure, we can say the population medians of both groups are not different.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
independence_test(ASO ~ group, data=groups, distribution=approximate(nresample=10000))
```

# Exercise 3

```{r, echo=TRUE, warning=FALSE, message=FALSE}
treatment <- c(rep('conventional',23), rep('alternative',24))
result <- c(rep('relapse',2),rep('no relapse',21), rep('relapse',8), rep('no relapse',16))
backpain <- data.frame(treatment=treatment, result=result)
backpain_tally <- tally(~treatment+result, data=backpain)
```

## Standard Method

We don't reject the null hypothesis, therefore there's no significant effect on relapse when treating using conventional methods versus alternative methods.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(backpain_tally)
```

## Resampling method

The resampling method confirms our results with the standard method. There's no significant differences.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(backpain_tally, simulate.p.value=TRUE, B=1000)
```

# Exercise 4

## (i)

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cont_table = matrix(c(17,298,230,428),nrow= 2,dimnames=list("seatbelt"=c("Y","N"),"head_injury"=c("Y","N")))
cont_table
```

## (ii)

Without running any tests we can see following:
The rate of having head injuries while wearing sealbelt (0.07) is much lower than while not wearing seatbelt (0.41).
```{r, echo=TRUE, warning=FALSE, message=FALSE}
17/247
298/726
```

### (iii)

The expected counts for the contingency table are as follows:

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table)$expected
```

### (iv)

#### Standard procedures

We can reject the null hypothesis, therefore there is a significant effect of wearing a seatbelt in order to prevent head injuries.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table)
```

#### Resampling procedures

Just as the standard procedure explains, we can conclude that wearing a seatbelt does indeed prevent head injuries.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table, simulate.p.value=TRUE, B=10000)
```

# Exercise 5

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cont_table = matrix(c(6,17,37,2,13,44),nrow=2,ncol=3,byrow=T,dimnames=list("type"=c("active_drug","Placebo"), "ocular_discomfort"=c("2","3","4")))
cont_table
```

## Standard procedures

We can see that there are no significant differences between active drug and placebo patients for this test.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table)
```

## Resampling procedures

The resampling procedure also corroborates with this result, therefore we can see no significant difference between active drug and placebo patients through this method either.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table, simulate.p.value=TRUE, B=10000)
```

# Exercise 6

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cont_table = matrix(c(23,45,17,1064,25,51,19,1043),nrow=2,ncol=4,byrow=T,dimnames=list("type"=c("Angioplasty","Medical therapy"), "Status"=c("Cardiac death","Other death","Unknown cause","Alive")))
cont_table
```

## Standard procedures

We can see that there doesn't seem to be any statistically significant association between treatment group and the outcome.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
chisq.test(cont_table)
```

# Exercise 7

```{r, echo=TRUE, warning=FALSE, message=FALSE}
id <- 1:10
before <- c(6.7, 7.4, 9.2, 9.6, 7.4, 8.1, 10.8, 7.1, 7.9, 10.8)
after <- c(7, 7.4, 8.6, 8.1, 6.8, 7, 8.5, 7.7, 9.7, 7.7)
diff <- before-after
ba <- data.frame(id=id, before=before, after=after, diff=diff)
```

## Paired t-test: Standard method

We can conclude that there are no differences among the results before and after the use of the insulin pump on HgbAlc.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
t.test(ba$before, ba$after ,paired=TRUE)
```

## Resampling procedure for paired t-test

Our resampling procedure returns a very similar p-value, therefore it corroborates our results.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
paired.perm.test(ba$diff)
```

# Exercise 8

```{r, echo=TRUE, warning=FALSE, message=FALSE}
caloric_intake <- c(50,70,90,120,40,100,150,110,75,160)
VO2 <- c(7,8,10.5,11,9,10.8,12,10,9.5,11.9)
```

## Testing normality

Testing normality using Shapiro-Wilk test results in enough statistical significance to claim that the samples come from a normal distribution.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
shapiro.test(caloric_intake)
shapiro.test(VO2)
```

## Pearson's correlation test

Looking at the result of our correlation test, we obtain a high correlation of ~ 0.88, which suggests there is a significant relationship between the two variables. Our p-value also rejects the null hypothesis that the true correlation is equal to zero. 

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cor.test(caloric_intake, VO2)
```

# Exercise 9

```{r, echo=TRUE, warning=FALSE, message=FALSE}
dbp <- read.table('./dbp.txt', header=TRUE)
```

## (i)

### Testing normality

According to our Shapiro-Wilk normality test, we obtain that these samples from either group A or B are probably not coming from a normally distributed population.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
shapiro.test(dbp[dbp$TRT == 'A','DBP'])
shapiro.test(dbp[dbp$TRT == 'B','DBP'])
```

### Wilcoxon-Mann-Whitney test using resampling

According to our test we reject the null hypothesis, therefore there are differences between the diastolic blood pressure of group A and group B.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
wilcox_test(DBP~factor(TRT),data=dbp,distribution=approximate(nresample=10000))
```

### Wilcoxon-Mann-Whitney test using resampling over time

Same results are obtained through the Wilcoxon-Mann-Whitney test using resampling over time (stratified by month).

```{r, echo=TRUE, warning=FALSE, message=FALSE}
dbp$TRT <- factor(dbp$TRT)
dbp$month <- factor(dbp$month)
dbp <- as.data.frame(dbp)
wilcox_test(DBP~TRT|month,data=dbp,distribution=approximate(nresample=10000))
```

# Exercise 10

```{r, echo=TRUE, warning=FALSE, message=FALSE}
cont_table = matrix(c(13,37-13,170-13,699-170-37+13),nrow= 2, byrow=T,dimnames=list("control"=c("Y","N"),"case"=c("Y","N")))
```

## McNemar's test

### Standard method
 
According to our test, there are difference among the hazard and control groups. Therefore the use of a cellular telephone while driving is associated with a significant increase in car accident rate.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
mcnemar.test(cont_table, correct = FALSE)
```

### Resampling method

The resampling test returns the same results as the standard test, therefore we can decisively conclude that there's statistical evidence to state that it is most likely significantly more dangerous to use the phone while driving than not.

```{r, echo=TRUE, warning=FALSE, message=FALSE}
mh_test(as.table(cont_table), distribution = approximate(nresample =10000))
```

# Exercise 11

## Resume the main ideas about the False Discovery Rate (FDR). 

False discoveries are the number of false positives, which is the type I error (when you incorrectly reject the null hypothesis). 
Consequently, false discovery rate is the expectation of the proportion of false discoveries among all the discoveries (rejections of all the null hypothesis). 

Proportion of false discoveries: 

$$Q = \frac{V} R = \frac{V}{(V+S)}$$
where *V* is the number of false discoveries, *S* is the number of true positives (true discoveries), and $$R=V+S$$ which is the total number of rejected null hypotheses (discoveries).  

$$FDR = Q_e = E[Q]$$
Formally, it can be written as follows, 

$$FDR = E[\frac{V} R | R > 0] * P[ R > 0]$$
Additionally, false discovery rate (FDR) can be used as a method of conceptualizing the rate of type I error in null hypothesis testing when conducting multiple comparisons.

In medical testing, the FDR is getting a "positive" test result but without actually having the disease, it's the complement of the Positive Predictive Value(PPV), which tells the probability of a positive test result being accurate. 

## Explain the Benjamini-Hochberg and the q-Value procedures. 

It is a FDR approach which adjusts the p-value for a series of tests. 

P-value gives the probability of a false positive on one single test. Instead of that, q-value gives the proportion of false positives of all the tests done. It is a better critical value to use when running a large number of tests from small samples.

Q-value is the infumum of the probability that H0 is true given that H0 is rejected (the false discovery rate).

B-H procedure is a procedure that decreases the FDR, the steps are as follows: 

1. Take the individual p-values in ascending order; 
2. Assign ranks to each p-value with the smallest rank 1;
3. Calculate each p-values's B-H critical value by using formula $(\frac{i} m)*Q$ where *i* is the individual p-value's rank, *m* is the total number of tests done and *Q* is the false discovery rate chosen by the user;
4. Compare the original p-values to the critical B-H from step 3 and find the largest p-value that is smaller than the critical value. 

## Show examples of application with R with a comparison between both methods.

Suppose we have done a test related with food, and the data are as follows, the first column indicates each type of food and the second row shows the exact p-value of multiple test of each observation. 

\footnotesize

```{r, echo=TRUE, warning=FALSE, message=FALSE}
Input = ("
  Food               pvalues
  Blue_fish          .34
  Bread              .594
  Butter             .212
  Carbohydrates      .384
  Cereals_and_pasta  .074
  Dairy_products     .94
  Eggs               .275
  Fats               .696
  Fruit              .269
  Legumes            .341
  Nuts               .06
  Olive_oil          .008
  Potatoes           .569
  Processed_meat     .986
  Proteins           .042
  Red_meat           .251
  Semi-skimmed_milk  .942
  Skimmed_milk       .222
  Sweets             .762
  Total_calories     .001
  Total_meat         .975
  Vegetables         .216
  White_fish         .205
  White_meat         .041
  Whole_milk         .039
")
Data11 = read.table(textConnection(Input), header = TRUE)
```

\normalsize

We order the data by the p-values
```{r, echo=TRUE, warning=FALSE, message=FALSE}
Data11 = Data11[order(Data11$pvalues),]
```

Obtaining the adjusted p-values by using the method Benjamini-Hochberg and q-values, they are the same. We can observe that after adjusting the p-values, we reject only the first hypothesis test instead of rejecting 5.  

\footnotesize

```{r, echo=TRUE, warning=FALSE, message=FALSE}
Data11$BH = p.adjust(Data11$pvalues,method = "BH")
Data11$qvalues = qvalue(Data11$pvalues)$qvalues
Data11
```

\normalsize